# Voice2Action - Technical Specification

## 1. System Overview

### 1.1 Purpose
Voice2Action is an AI-powered system that transforms voice recordings from meetings and calls into actionable documentation, tasks, and analytics. The system processes audio through speech recognition, natural language analysis, and automated task management.

### 1.2 Key Components
- **Telegram Bot**: Primary user interface for mobile users
- **Web Application**: Browser-based interface for desktop users
- **AI Processing Pipeline**: Whisper (transcription) + GPT-4o-mini (analysis)
- **Integration Layer**: Jira, Google Docs, Confluence connectors
- **Backend API**: Python FastAPI service

### 1.3 User Flow Summary
```
Audio Input ‚Üí Transcription ‚Üí AI Analysis ‚Üí Task Creation ‚Üí Delivery
(User)        (Whisper)      (GPT-4o)      (Jira API)     (Response)
```

---

## 2. Telegram Bot Workflow

### 2.1 User Interaction
**Trigger**: User sends voice message or audio file to `@voice2action_bot`

**Supported formats**:
- Voice messages (OGG/OPUS)
- Audio files (MP3, M4A, WAV, OGG)
- Maximum duration: 180 minutes
- Maximum file size: 100 MB

### 2.2 Processing Pipeline

#### Step 1: Audio Reception
```python
async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    user_id = message.from_user.id
    
    # Identify audio type
    if message.voice:
        file = await message.voice.get_file()
        file_path = f'temp_{file.file_id}.ogg'
    elif message.audio:
        file = await message.audio.get_file()
        file_path = f'temp_{file.file_id}.mp3'
    
    # Download file
    await file.download_to_drive(file_path)
    await message.reply_text('üéß –ê—É–¥–∏–æ –ø–æ–ª—É—á–µ–Ω–æ! –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...')
```

**Actions**:
1. Validate file format and size
2. Download to temporary storage (`/tmp/` directory)
3. Generate unique file ID for tracking
4. Send confirmation message to user

#### Step 1.5: Audio Chunking (for files >30 min)
```python
# services/audio_utils.py
from pydub import AudioSegment
import os

def get_duration(file_path):
    audio = AudioSegment.from_file(file_path)
    return len(audio) / 1000.0

def split_audio(file_path, chunk_sec=1800):  # 30 –º–∏–Ω
    audio = AudioSegment.from_file(file_path)
    duration_ms = len(audio)
    chunks = []
    for i in range(0, duration_ms, chunk_sec * 1000):
        chunk = audio[i:i + chunk_sec * 1000]
        path = f"/tmp/chunk_{os.getpid()}_{i}.mp3"
        chunk.export(path, format="mp3")
        chunks.append(path)
    return chunks
```

#### Step 2: Audio Conversion (if needed)
```python
# Convert OGG/OPUS to MP3 for better compatibility
if file_path.endswith('.ogg'):
    mp3_path = file_path.replace('.ogg', '.mp3')
    # Use pydub or ffmpeg
    AudioSegment.from_ogg(file_path).export(mp3_path, format='mp3')
    file_path = mp3_path
```

**Requirements**:
- Ensure consistent audio format for Whisper
- Preserve audio quality (minimum 16kHz sampling rate)
- Handle corrupted files gracefully

#### Step 3: Transcription (OpenAI Whisper)
```python
from services.audio_utils import get_duration, split_audio
import asyncio
import os

async def transcribe_audio(file_path: str) -> dict:
    duration = get_duration(file_path)
    
    # –ï—Å–ª–∏ >30 –º–∏–Ω ‚Äî —Ä–∞–∑–±–∏–≤–∞–µ–º
    if duration > 1800:
        print(f"[INFO] –ê—É–¥–∏–æ >30 –º–∏–Ω ({duration:.1f}—Å). –†–∞–∑–±–∏–≤–∞–µ–º...")
        chunks = split_audio(file_path)
        full_text = ""
        segments = []
        offset = 0
        
        for idx, chunk in enumerate(chunks):
            print(f"[INFO] –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–∞—Å—Ç–∏ {idx+1}/{len(chunks)}")
            try:
                with open(chunk, "rb") as f:
                    result = openai_client.audio.transcriptions.create(
                        model="whisper-1",
                        file=f,
                        language="ru",
                        response_format="verbose_json",
                        temperature=0.2
                    )
                # –°–¥–≤–∏–≥–∞–µ–º —Ç–∞–π–º–∫–æ–¥—ã
                for seg in result.segments:
                    seg["start"] += offset
                    seg["end"] += offset
                    segments.append(seg)
                full_text += result.text + " "
                offset += get_duration(chunk)
            finally:
                if os.path.exists(chunk):
                    os.remove(chunk)
        
        return {"text": full_text.strip(), "segments": segments, "duration": duration}
    
    # –û–±—ã—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
    else:
        with open(file_path, "rb") as f:
            result = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                language="ru",
                response_format="verbose_json",
                temperature=0.2
            )
        return {
            "text": result.text,
            "segments": result.segments,
            "duration": duration
        }
```

**API Parameters**:
- `model`: `whisper-1` (most accurate)
- `language`: `ru` (Russian, auto-detect if needed)
- `response_format`: `verbose_json` (includes timestamps)
- `temperature`: `0.0-0.2` (lower = more accurate)

**Error Handling**:
- Timeout: Retry up to 3 times with exponential backoff
- Invalid audio: Notify user "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ"
- API quota exceeded: Queue request for later processing

**Expected Output**:
```json
{
  "text": "–î–æ–±—Ä—ã–π –¥–µ–Ω—å –∫–æ–ª–ª–µ–≥–∏. –û–±—Å—É–¥–∏–º –∑–∞–¥–∞—á–∏ –Ω–∞ —Å–ø—Ä–∏–Ω—Ç...",
  "segments": [
    {"start": 0.0, "end": 3.5, "text": "–î–æ–±—Ä—ã–π –¥–µ–Ω—å –∫–æ–ª–ª–µ–≥–∏."},
    {"start": 3.5, "end": 7.2, "text": "–û–±—Å—É–¥–∏–º –∑–∞–¥–∞—á–∏ –Ω–∞ —Å–ø—Ä–∏–Ω—Ç..."}
  ],
  "language": "ru"
}
```

#### Step 4: AI Analysis (GPT-4o-mini)

#### Step 4.1: Select Analysis Type
```python
## –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ
from telegram import InlineKeyboardMarkup, InlineKeyboardButton

await message.reply_text(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:",
    reply_markup=InlineKeyboardMarkup([
        [InlineKeyboardButton("–í—Å—Ç—Ä–µ—á–∞", callback_data="analysis_meeting")],
        [InlineKeyboardButton("–ü—Ä–æ–¥–∞–∂–∏", callback_data="analysis_sales")],
        [InlineKeyboardButton("–ò–Ω—Ç–µ—Ä–≤—å—é", callback_data="analysis_interview")],
        [InlineKeyboardButton("–ö–∞—Å—Ç–æ–º", callback_data="analysis_custom")],
    ])
)
# –°–æ—Ö—Ä–∞–Ω–∏ –≤—ã–±–æ—Ä
context.user_data['analysis_type'] = query.data.split("_")[1]
```
```python
prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤—Å—Ç—Ä–µ—á–∏ –∏ –≤—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–µ–µ:

**–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:**
{transcript.text}

**–ó–∞–¥–∞—á–∏:**
1. –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (summary) –≤—Å—Ç—Ä–µ—á–∏ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π).
2. –ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ –∑–∞–¥–∞—á–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
   - –ó–∞–¥–∞—á–∞: [–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ]
   - –î–µ–¥–ª–∞–π–Ω: [–î–∞—Ç–∞ –∏–ª–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"]
   - –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: [–ò–º—è –∏–ª–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"]
   
3. –ï—Å–ª–∏ —ç—Ç–æ –∑–≤–æ–Ω–æ–∫ –ø—Ä–æ–¥–∞–∂, –¥–æ–±–∞–≤—å –∞–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è:
   - –°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã (—ç—ç—ç, –º–º–º, —Ç–∏–ø–∞)
   - –î–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—É–∑—ã (>3 —Å–µ–∫—É–Ω–¥)
   - –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ—á–∏ (–í—ã—Å–æ–∫–∞—è/–°—Ä–µ–¥–Ω—è—è/–ù–∏–∑–∫–∞—è)
   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è

**–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:**
## Summary
[–†–µ–∑—é–º–µ –≤—Å—Ç—Ä–µ—á–∏]

## –ó–∞–¥–∞—á–∏
1. –ó–∞–¥–∞—á–∞: [–û–ø–∏—Å–∞–Ω–∏–µ]
   –î–µ–¥–ª–∞–π–Ω: [–î–∞—Ç–∞]
   –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: [–ò–º—è]

## –ê–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
[–ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏]
"""

response = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–µ–ª–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á –∏ –∑–≤–æ–Ω–∫–æ–≤."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.3,
    max_tokens=1500
)

analysis = response.choices[0].message.content
```

**Prompt Engineering Best Practices**:
- Clear structure with numbered instructions
- Explicit output format (markdown sections)
- Contextual awareness (sales call vs meeting)
- Fallback for missing information ("–ù–µ —É–∫–∞–∑–∞–Ω")

**Expected Output**:
```markdown
## Summary
–û–±—Å—É–∂–¥–µ–Ω–∏–µ —Å–ø—Ä–∏–Ω—Ç–∞ 45. –ö–æ–º–∞–Ω–¥–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∞ 5 –∑–∞–¥–∞—á –Ω–∞ –Ω–µ–¥–µ–ª—é. –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–∫—É—Å - —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥—É–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –Ω–æ–≤—ã–π API endpoint.

## –ó–∞–¥–∞—á–∏
1. –ó–∞–¥–∞—á–∞: –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥—É–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
   –î–µ–¥–ª–∞–π–Ω: 2025-11-08
   –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: –ê–ª–µ–∫—Å–µ–π

2. –ó–∞–¥–∞—á–∞: –°–æ–∑–¥–∞—Ç—å API –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–æ–≤
   –î–µ–¥–ª–∞–π–Ω: 2025-11-10
   –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: –ú–∞—Ä–∏—è

## –ê–Ω–∞–ª–∏–∑
–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ—á–∏: –í—ã—Å–æ–∫–∞—è
–°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã: 3 —Å–ª—É—á–∞—è ("—ç—ç—ç")
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –û—Ç–ª–∏—á–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è, —á–µ—Ç–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
```

#### Step 5: Jira Integration
```python
# Parse tasks from GPT response
tasks = parse_tasks_from_analysis(analysis)

created_issues = []
for task in tasks:
    issue = jira.issue_create(
        fields={
            'project': {'key': JIRA_PROJECT_KEY},  # e.g., "V2A"
            'summary': task['description'],
            'description': f"""
–ò—Å—Ç–æ—á–Ω–∏–∫: Voice2Action Bot
–°–æ–∑–¥–∞–Ω–æ: {datetime.now().isoformat()}
–î–µ–¥–ª–∞–π–Ω: {task['deadline']}
–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: {task['assignee']}

–ü–æ–ª–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:
{transcript.text[:500]}...
            """,
            'issuetype': {'name': 'Task'},
            'priority': {'name': 'Medium'},
            'duedate': task['deadline'] if task['deadline'] != '–ù–µ —É–∫–∞–∑–∞–Ω' else None
        }
    )
    
    created_issues.append({
        'key': issue['key'],
        'url': f"{JIRA_URL}/browse/{issue['key']}"
    })
```

**Jira API Requirements**:
- Authentication: Basic Auth (email + API token) or OAuth 2.0
- Endpoint: `POST /rest/api/3/issue`
- Fields: `project`, `summary`, `description`, `issuetype`, `duedate`
- Error handling: Handle duplicate issues, invalid project keys

**Rate Limiting**:
- Jira Cloud: 100 requests/minute
- Implement exponential backoff on 429 errors

#### Step 6: Google Docs Export (Optional)
```python
# Create document via Google Docs API
from googleapiclient.discovery import build

service = build('docs', 'v1', credentials=creds)

document = service.documents().create(
    body={
        'title': f'Voice2Action Protocol - {datetime.now().strftime("%Y-%m-%d %H:%M")}'
    }
).execute()

doc_id = document['documentId']

# Insert content
requests = [
    {
        'insertText': {
            'location': {'index': 1},
            'text': f"{analysis}\n\n--- –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç ---\n{transcript.text}"
        }
    }
]

service.documents().batchUpdate(
    documentId=doc_id,
    body={'requests': requests}
).execute()

doc_url = f"https://docs.google.com/document/d/{doc_id}/edit"
```

**Google API Setup**:
- Enable Google Docs API in Cloud Console
- OAuth 2.0 credentials with `docs` scope
- Service account for server-to-server auth
- Share document publicly or with specific users

**Fallback Strategy** (if API unavailable):
- Generate markdown file
- Upload to file hosting (Dropbox, OneDrive)
- Send direct link to user

#### Step 7: Response to User

###  **Step 7.1: Export Options**

```markdown
#### Step 7.1: Export Options
```python
await message.reply_text(
    "–ö—É–¥–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å?",
    reply_markup=InlineKeyboardMarkup([
        [InlineKeyboardButton("Excel", callback_data="export_excel")],
        [InlineKeyboardButton("Word", callback_data="export_word")],
        [InlineKeyboardButton("Jira", callback_data="export_jira")],
        [InlineKeyboardButton("Google Docs", callback_data="export_gdocs")],
    ])
)
```
## Excel Export (services/excel_generator.py)
```python
from openpyxl import Workbook

from openpyxl.styles import Font, PatternFill

def generate_excel(analysis, transcript=None):
    wb = Workbook()
    ws = wb.active
    ws.title = "Summary"
    ws['A1'] = "–ê–Ω–∞–ª–∏–∑ –≤—Å—Ç—Ä–µ—á–∏"
    ws['A1'].font = Font(size=16, bold=True)
    # ... (–≤–µ—Å—å –∫–æ–¥ –∏–∑ v2.0)
    path = f"/tmp/analysis_{job_id}.xlsx"
    wb.save(path)
    return path
```

Word Export (services/word_generator.py)
```python
from docx import Document

def generate_word(analysis, transcript=None):
    doc = Document()
    doc.add_heading('–ü–†–û–¢–û–ö–û–õ –í–°–¢–†–ï–ß–ò', 0)
    # ... (–≤–µ—Å—å –∫–æ–¥ –∏–∑ v2.0)
    path = f"/tmp/protocol_{job_id}.docx"
    doc.save(path)
    return path
```

```python
response_message = f"""
‚úÖ **–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**

üìù **Summary:**
{extract_summary(analysis)}

üìã **–ó–∞–¥–∞—á–∏:**
{format_tasks_for_telegram(tasks)}

üîó **–°—Å—ã–ª–∫–∏:**
{format_jira_links(created_issues)}
{f"üìÑ [Google Doc]({doc_url})" if doc_url else ""}

‚è± –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.1f} —Å–µ–∫
"""

await message.reply_text(
    response_message,
    parse_mode='Markdown',
    disable_web_page_preview=True
)

# Cleanup temp files
os.remove(file_path)
```

**Message Formatting**:
- Use Telegram markdown (bold, links, lists)
- Include emojis for visual clarity
- Limit message length (4096 chars max)
- Split long messages if needed

---

## 3. Web Application Workflow

### 3.1 User Interface
**URL**: `https://voice2action.ai/app`

**Features**:
- Drag-and-drop audio upload
- File selection dialog (button)
- Progress indicator during processing
- Real-time status updates via WebSocket

### 3.2 Frontend Implementation

#### HTML Structure
```html
<!-- app.html -->
<div class="upload-section">
  <div class="drop-zone" id="dropZone">
    <p>–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å—é–¥–∞ –∏–ª–∏</p>
    <button class="btn primary-btn" onclick="document.getElementById('fileInput').click()">
      –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª
    </button>
    <input type="file" id="fileInput" accept="audio/*" hidden>
  </div>
  
  <div class="progress-container" id="progressContainer" hidden>
    <div class="progress-bar">
      <div class="progress-fill" id="progressFill"></div>
    </div>
    <p class="progress-text" id="progressText">–ó–∞–≥—Ä—É–∑–∫–∞...</p>
  </div>
  
  <div class="results-container" id="resultsContainer" hidden>
    <!-- Results will be injected here -->
  </div>
</div>
```

#### JavaScript Upload Handler
```javascript
// app.js
const fileInput = document.getElementById('fileInput');
const dropZone = document.getElementById('dropZone');
const progressContainer = document.getElementById('progressContainer');
const resultsContainer = document.getElementById('resultsContainer');

fileInput.addEventListener('change', handleFileUpload);
dropZone.addEventListener('drop', handleDrop);
dropZone.addEventListener('dragover', (e) => e.preventDefault());

async function handleFileUpload(event) {
  const file = event.target.files[0];
  if (!file) return;
  
  // Validate file
  const validTypes = ['audio/mpeg', 'audio/ogg', 'audio/wav', 'audio/mp4'];
  if (!validTypes.includes(file.type)) {
    alert('–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ MP3, OGG, WAV –∏–ª–∏ M4A.');
    return;
  }
  
  if (file.size > 20 * 1024 * 1024) { // 20 MB
    alert('–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º 20 –ú–ë.');
    return;
  }
  
  // Show progress
  dropZone.hidden = true;
  progressContainer.hidden = false;
  updateProgress(0, '–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞...');
  
  // Upload to backend
  const formData = new FormData();
  formData.append('audio', file);
  
  try {
    const response = await fetch('/api/process-audio', {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) throw new Error('Upload failed');
    
    // Poll for results
    const jobId = (await response.json()).job_id;
    pollProcessingStatus(jobId);
    
  } catch (error) {
    showError('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: ' + error.message);
  }
}

async function pollProcessingStatus(jobId) {
  const interval = setInterval(async () => {
    const response = await fetch(`/api/status/${jobId}`);
    const data = await response.json();
    
    updateProgress(data.progress, data.status);
    
    if (data.complete) {
      clearInterval(interval);
      displayResults(data.results);
    }
    
    if (data.error) {
      clearInterval(interval);
      showError(data.error);
    }
  }, 2000); // Poll every 2 seconds
}

function displayResults(results) {
  progressContainer.hidden = true;
  resultsContainer.hidden = false;
  
  resultsContainer.innerHTML = `
    <h2>‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞</h2>
    
    <section class="summary-section">
      <h3>üìù Summary</h3>
      <p>${results.summary}</p>
    </section>
    
    <section class="tasks-section">
      <h3>üìã –ó–∞–¥–∞—á–∏</h3>
      <ul>
        ${results.tasks.map(task => `
          <li>
            <strong>${task.description}</strong><br>
            –î–µ–¥–ª–∞–π–Ω: ${task.deadline} | –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: ${task.assignee}
          </li>
        `).join('')}
      </ul>
    </section>
    
    <section class="links-section">
      <h3>üîó –°—Å—ã–ª–∫–∏</h3>
      ${results.jira_issues.map(issue => `
        <a href="${issue.url}" target="_blank">${issue.key}</a>
      `).join(' | ')}
      ${results.doc_url ? `<br><a href="${results.doc_url}" target="_blank">üìÑ Google Doc</a>` : ''}
    </section>
    
    <button class="btn secondary" onclick="resetForm()">
      –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ—â—ë –æ–¥–∏–Ω —Ñ–∞–π–ª
    </button>
  `;
}
```

### 3.3 Backend API

#### FastAPI Endpoints
```python
from fastapi import FastAPI, UploadFile, BackgroundTasks
from fastapi.responses import JSONResponse
import uuid

app = FastAPI()

# In-memory job storage (use Redis in production)
jobs = {}

@app.post("/api/export")
async def export_results(request: ExportRequest, background: BackgroundTasks):
    job = await get_job(request.job_id)
    if not job.complete:
        raise HTTPException(400, "Job not completed")
    
    results = []
    if "excel" in request.exports:
        path = generate_excel(job.results)
        background.add_task(os.remove, path)  # cleanup
        results.append({"type": "excel", "url": f"/download/excel/{job.id}"})
    
    return {"exports": results}

@app.post("/api/process-audio")
async def process_audio(audio: UploadFile, background_tasks: BackgroundTasks):
    """
    Endpoint to upload audio file and start processing
    """
    # Validate file
    if audio.content_type not in ['audio/mpeg', 'audio/ogg', 'audio/wav']:
        return JSONResponse(
            status_code=400,
            content={"error": "Invalid file type"}
        )
    
    # Generate job ID
    job_id = str(uuid.uuid4())
    
    # Save file temporarily
    file_path = f"/tmp/{job_id}_{audio.filename}"
    with open(file_path, "wb") as f:
        f.write(await audio.read())
    
    # Initialize job status
    jobs[job_id] = {
        "status": "queued",
        "progress": 0,
        "complete": False,
        "error": None,
        "results": None
    }
    
    # Start background processing
    background_tasks.add_task(process_audio_pipeline, job_id, file_path)
    
    return {"job_id": job_id}

@app.get("/api/status/{job_id}")
async def get_status(job_id: str):
    """
    Poll endpoint for job status
    """
    if job_id not in jobs:
        return JSONResponse(status_code=404, content={"error": "Job not found"})
    
    return jobs[job_id]

async def process_audio_pipeline(job_id: str, file_path: str):
    """
    Background task for audio processing
    """
    try:
        # Step 1: Transcription
        jobs[job_id].update({"status": "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è...", "progress": 20})
        transcript = await transcribe_audio(file_path)
        
        # Step 2: AI Analysis
        jobs[job_id].update({"status": "–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞...", "progress": 50})
        analysis = await analyze_transcript(transcript)
        
        # Step 3: Jira Integration
        jobs[job_id].update({"status": "–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á...", "progress": 75})
        jira_issues = await create_jira_issues(analysis['tasks'])
        
        # Step 4: Google Docs (optional)
        jobs[job_id].update({"status": "–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞...", "progress": 90})
        doc_url = await create_google_doc(transcript, analysis)
        
        # Complete
        jobs[job_id].update({
            "status": "–ì–æ—Ç–æ–≤–æ",
            "progress": 100,
            "complete": True,
            "results": {
                "summary": analysis['summary'],
                "tasks": analysis['tasks'],
                "jira_issues": jira_issues,
                "doc_url": doc_url
            }
        })
        
    except Exception as e:
        jobs[job_id].update({
            "status": "–û—à–∏–±–∫–∞",
            "error": str(e),
            "complete": True
        })
    
    finally:
        # Cleanup
        os.remove(file_path)
```

---

## 4. Data Flow Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Input    ‚îÇ
‚îÇ  (Audio File)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  File Storage   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ Validation (format, size)
‚îÇ   (Temp /tmp)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OpenAI Whisper  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ API Call (30-120s)
‚îÇ  Transcription  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GPT-4o-mini    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ Prompt Engineering
‚îÇ    Analysis     ‚îÇ      (Summary + Tasks + Style)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                     ‚îÇ
         ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Jira REST     ‚îÇ   ‚îÇ  Google Docs    ‚îÇ
‚îÇ      API        ‚îÇ   ‚îÇ      API        ‚îÇ
‚îÇ (Create Issues) ‚îÇ   ‚îÇ (Create Doc)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Response to   ‚îÇ
         ‚îÇ      User       ‚îÇ
         ‚îÇ (Telegram/Web)  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 5. Error Handling & Edge Cases

### 5.1 Audio Processing Errors

| Error | Cause | Handling |
|-------|-------|----------|
| `Invalid format` | Unsupported file type | Notify user, suggest MP3/OGG |
| `File too large` | >20 MB | Notify user, request shorter audio |
| `Corrupted audio` | Damaged file | Notify user to re-record |
| `Empty audio` | Silent recording | Notify user "–ê—É–¥–∏–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ—á–∏" |

### 5.2 API Errors

| Error | Cause | Handling |
|-------|-------|----------|
| `Whisper timeout` | Large file, slow API | Retry 3x with backoff, then notify |
| `GPT rate limit` | Too many requests | Queue job, process when quota available |
| `Jira auth failed` | Invalid credentials | Log error, skip Jira, continue with summary |
| `Google Docs quota` | Daily limit exceeded | Skip Doc creation, use markdown export |

### 5.3 Network Issues
- **Telegram bot disconnect**: Automatic reconnection via `python-telegram-bot`
- **API downtime**: Fallback to cached responses or queue for later
- **Database unavailable**: Use in-memory storage temporarily

---

## 6. Performance Requirements

### 6.1 Response Times
- **Telegram bot response**: <2 seconds for acknowledgment
- **Transcription (Whisper)**: 30-120 seconds (depends on audio length)
- **AI analysis (GPT-4o-mini)**: 5-15 seconds
- **Jira ticket creation**: 2-5 seconds per task
- **Total pipeline**: <3 minutes for 10-minute audio

### 6.2 Scalability
- **Concurrent users**: Support 100+ simultaneous requests
- **Daily processing**: 1,000+ audio files per day
- **Storage**: Auto-delete temp files after 24 hours
- **Rate limiting**: 10 requests/minute per user

### 6.3 Uptime
- **Telegram bot**: 99.5% uptime (monitored via UptimeRobot)
- **Web app**: 99.9% uptime (hosted on Render.com)
- **Database**: PostgreSQL with automatic backups

---

## 7. Security & Privacy

### 7.1 Data Protection
- **Encryption in transit**: HTTPS/TLS for all API calls
- **Encryption at rest**: AES-256 for stored audio (if needed)
- **Data retention**: Audio deleted after processing (max 24h)
- **GDPR compliance**: User consent for data processing

### 7.2 Authentication
- **Telegram bot**: User authentication via Telegram ID
- **Web app**: JWT tokens for session management
- **API keys**: Stored in `.env`, rotated quarterly
- **OAuth 2.0**: For Jira and Google Docs integrations

### 7.3 Rate Limiting
- **Per user**: 10 requests/hour
- **Global**: 1,000 requests/hour
- **DDoS protection**: Cloudflare or similar CDN

---

## 8. Testing Strategy

### 8.1 Unit Tests
```python
def test_audio_download():
    """Test Telegram file download"""
    assert download_audio(mock_file_id) == "temp_file.ogg"

def test_transcription():
    """Test Whisper API call"""
    transcript = transcribe_audio("test_audio.mp3")
    assert len(transcript) > 0
    assert transcript.language == "ru"

def test_task_parsing():
    """Test GPT response parsing"""
    analysis = """
    ## –ó–∞–¥–∞—á–∏
    1. –ó–∞–¥–∞—á–∞: Test task
       –î–µ–¥–ª–∞–π–Ω: 2025-11-10
       –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: John
    """
    tasks = parse_tasks(analysis)
    assert len(tasks) == 1
    assert tasks[0]['description'] == "Test task"
```

### 8.2 Integration Tests
```python
def test_end_to_end_telegram():
    """Test full Telegram bot workflow"""
    # 1. Send audio to bot
    bot.send_voice(chat_id=TEST_USER_ID, voice=open("test.ogg", "rb"))
    
    # 2. Wait for processing
    time.sleep(120)
    
    # 3. Check response
    updates = bot.get_updates()
    assert "Summary:" in updates[-1].message.text
    assert "–ó–∞–¥–∞—á–∏:" in updates[-1].message.text

def test_jira_integration():
    """Test Jira ticket creation"""
    issue = create_jira_issue({
        'description': 'Test task',
        'deadline': '2025-11-10',
        'assignee': 'testuser'
    })
    assert issue['key'].startswith('V2A-')
```

### 8.3 Load Testing
```python
# locust_test.py
from locust import HttpUser, task, between

class Voice2ActionUser(HttpUser):
    wait_time = between(5, 15)
    
    @task
    def upload_audio(self):
        with open("test_audio.mp3", "rb") as f:
            self.client.post("/api/process-audio", files={"audio": f})
    
    @task
    def poll_status(self):
        self.client.get(f"/api/status/{self.job_id}")
```

Run: `locust -f locust_test.py --users 100 --spawn-rate 10`

---

## 9. Deployment

### 9.1 Telegram Bot (Render.com)
```yaml
# render.yaml
services:
  - type: worker
    name: voice2action-bot
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: python telegram-bot/bot.py
    envVars:
      - key: TELEGRAM_TOKEN
        sync: false
      - key: OPENAI_API_KEY
        sync: false
      - key: JIRA_URL
        sync: false
```

### 9.2 Web Application (Render.com)
```yaml
services:
  - type: web
    name: voice2action-web
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: DATABASE_URL
        sync: false
```

### 9.3 Static Website (GitHub Pages)
```yaml
# .github/workflows/deploy.yml
name: Deploy to GitHub Pages

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Deploy
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./
```

---

## 10. Monitoring & Analytics

### 10.1 Metrics to Track
- **Processing time**: Average time per audio file
- **Success rate**: % of successful transcriptions
- **Error rate**: % of failed requests
- **User engagement**: Daily/weekly active users
- **API costs**: OpenAI usage (Whisper + GPT)

### 10.2 Logging
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('voice2action.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Log key events
logger.info(f"User {user_id} uploaded audio file {file_id}")
logger.info(f"Transcription completed in {elapsed_time:.2f}s")
logger.warning(f"Jira API rate limit hit, retrying in {backoff_time}s")
logger.error(f"Failed to process audio: {error_message}")
```

### 10.3 Alerts
- **Bot downtime**: Email/SMS if bot offline >5 minutes
- **High error rate**: Alert if >10% requests fail
- **API quota**: Warning at 80% of daily limit
- **Disk space**: Alert if <10% free space

---

## 11. Future Enhancements (Roadmap)

### Phase 1 (MVP) - Completed ‚úÖ
- Telegram bot with voice message support
- Whisper transcription
- GPT-4o-mini analysis
- Jira integration
- Static website

### Phase 2 (Q1 2026)
- Real-time processing during Zoom calls
- Confluence page creation
- Notion database sync
- Excel export (sales analytics)
- User dashboard (web app)

### Phase 3 (Q2 2026)
- Mobile app (iOS/Android)
- Multi-language support (EN, DE, FR)
- Custom AI prompts (user-defined)
- Team collaboration features
- Advanced analytics (sentiment analysis)

### Phase 4 (Q3 2026)
- On-premise deployment option
- Enterprise SSO integration
- Custom integrations (Slack, MS Teams)
- Voice command system ("–°–æ–∑–¥–∞–π –∑–∞–¥–∞—á—É –¥–ª—è –ê–ª–µ–∫—Å–µ—è")
- AI training on company data

---

## 12. API Documentation

### 12.1 Telegram Bot Commands

| Command | Description | Example |
|---------|-------------|---------|
| `/start` | Welcome message + instructions | `/start` |
| `/help` | List of features + examples | `/help` |
| `/feedback [text]` | Send feedback to developers | `/feedback –û—Ç–ª–∏—á–Ω—ã–π –±–æ—Ç!` |
| Voice message | Process audio ‚Üí summary + tasks | [Send voice] |
| Audio file | Process uploaded file | [Upload MP3] |

#### POST /api/process-audio
**Upload audio file for processing**

**Request**:
```http
POST /api/process-audio
Content-Type: multipart/form-data

audio: [binary file]
analysis_type: meeting | sales | interview | custom  (optional)
custom_prompt: "..."  (if analysis_type=custom)

if analysis_type == 'sales':
    prompt = SALES_ANALYSIS_PROMPT.format(transcript=transcript.text)
elif analysis_type == 'interview':
    prompt = INTERVIEW_ANALYSIS_PROMPT.format(transcript=transcript.text)
elif analysis_type == 'custom':
    custom = context.user_data.get('custom_prompt', '')
    prompt = custom or DEFAULT_PROMPT.format(transcript=transcript.text)
else:
    prompt = MEETING_SUMMARY_PROMPT.format(transcript=transcript.text)

response = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å—Ç—Ä–µ—á."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.3,
    max_tokens=1500
)
analysis = response.choices[0].message.content
```

**Response**:
```json
{
  "job_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "queued",
  "message": "–ê—É–¥–∏–æ –ø—Ä–∏–Ω—è—Ç–æ –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É"
}
```

#### GET /api/status/{job_id}
Check processing status

**Response (in progress)**:
```json
{
  "job_id": "a1b2c3d4-...",
  "status": "–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞...",
  "progress": 60,
  "stage": "GPT-4o-mini –∞–Ω–∞–ª–∏–∑",
  "eta_seconds": 25,
  "complete": false
}
```

**Response (when complete)**:
```json
{
  "job_id": "a1b2c3d4-...",
  "status": "–ì–æ—Ç–æ–≤–æ",
  "progress": 100,
  "complete": true,
  "results": {
    "summary": "–û–±—Å—É–∂–¥–µ–Ω–∏–µ —Å–ø—Ä–∏–Ω—Ç–∞ 45. –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ 5 –∑–∞–¥–∞—á...",
    "tasks": [
      {
        "title": "–†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏",
        "description": "–ü–µ—Ä–µ–ø–∏—Å–∞—Ç—å JWT –ª–æ–≥–∏–∫—É",
        "assignee": "–ê–ª–µ–∫—Å–µ–π",
        "deadline": "2025-11-08",
        "priority": "High"
      }
    ],
    "transcript": "–î–æ–±—Ä—ã–π –¥–µ–Ω—å –∫–æ–ª–ª–µ–≥–∏...",
    "duration_minutes": 47,
    "processing_time": 87.3
  }
}
```

---

#### POST /api/export

**Export results to selected destinations**  

*(–í—ã–∑—ã–≤–∞–µ—Ç—Å—è **–ø–æ—Å–ª–µ** –ø–æ–ª—É—á–µ–Ω–∏—è `complete: true`)*

**Request**:

```json
{
  "job_id": "a1b2c3d4-...",
  "exports": ["excel", "word", "jira", "google_docs"]
}

```
**Response**:
```json
{
  "job_id": "a1b2c3d4-...",
  "exports": {
    "excel": {
      "status": "success",
      "download_url": "/download/excel/a1b2c3d4.xlsx",
      "filename": "Meeting_Analysis_2025-11-02.xlsx"
    },
    "word": {
      "status": "success",
      "download_url": "/download/word/a1b2c3d4.docx",
      "filename": "Protocol_2025-11-02.docx"
    },
    "jira": {
      "status": "success",
      "issues": [
        { "key": "V2A-101", "url": "https://jira.company.com/browse/V2A-101" },
        { "key": "V2A-102", "url": "https://jira.company.com/browse/V2A-102" }
      ]
    },
    "google_docs": {
      "status": "success",
      "doc_url": "https://docs.google.com/document/d/abc123/edit"
    }
  }
}
```
---

#### GET /download/excel/{job_id}

**Download generated Excel file**
‚Üí Returns `.xlsx` file
‚Üí `Content-Disposition: attachment; filename="Meeting_Analysis_*.xlsx"`
---

#### GET /download/word/{job_id}

**Download generated Word protocol**

‚Üí Returns `.docx` file  

‚Üí `Content-Disposition: attachment; filename="Protocol_*.docx"`
---

#### POST /api/feedback

**Submit user feedback**

**Request**:
```json
{
  "user_id": "telegram_12345",
  "job_id": "a1b2c3d4-...",
  "message": "–û—Ç–ª–∏—á–Ω—ã–π —Å–µ—Ä–≤–∏—Å!",
  "rating": 5
}
```

**Response**:
```json
{
  "success": true,
  "message": "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤!"
}
```
---

## 13. Database Schema

### 13.1 PostgreSQL Tables
#### users
```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    telegram_id BIGINT UNIQUE,
    email VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW(),
    last_active TIMESTAMP,
    subscription_tier VARCHAR(20) DEFAULT 'free',
    api_calls_used INT DEFAULT 0,
    api_calls_limit INT DEFAULT 3
);
```
#### audio_processing_jobs
```sql
CREATE TABLE audio_processing_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id INT REFERENCES users(id) ON DELETE CASCADE,
    file_path VARCHAR(500),
    file_size_bytes BIGINT,
    duration_seconds INT,
    status VARCHAR(50) DEFAULT 'queued',
    progress INT DEFAULT 0,
    analysis_type VARCHAR(50),  -- meeting, sales, interview, custom
    transcript TEXT,
    analysis JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP,
    processing_time_seconds DECIMAL(10,2),
    api_cost_usd DECIMAL(10,4)
);
```
#### user_integrations
```sql
CREATE TABLE user_integrations (
    id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id) ON DELETE CASCADE,
    service VARCHAR(50) NOT NULL,
    credentials_encrypted TEXT NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(user_id, service)
);
```
#### exports
```sql
CREATE TABLE exports (
    id SERIAL PRIMARY KEY,
    job_id UUID REFERENCES audio_processing_jobs(id),
    export_type VARCHAR(50),
    file_path VARCHAR(500),
    external_url VARCHAR(500),
    created_at TIMESTAMP DEFAULT NOW()
);
```
### 13.2 Sample Queries

#### Get user processing history
```sql
SELECT 
  j.id,
  j.created_at,
  j.status,
  j.duration_seconds,
  COUNT(ji.id) as tasks_created
FROM audio_processing_jobs j
LEFT JOIN jira_issues ji ON j.id = ji.job_id
WHERE j.user_id = $1
GROUP BY j.id
ORDER BY j.created_at DESC
LIMIT 10;
```

#### Calculate monthly API costs
```sql
SELECT 
  DATE_TRUNC('month', created_at) as month,
  COUNT(*) as total_jobs,
  SUM(duration_seconds) as total_audio_seconds,
  -- Estimate costs: Whisper $0.006/min, GPT-4o-mini $0.15/1M tokens
  SUM(duration_seconds / 60.0 * 0.006) + 
  COUNT(*) * 0.0005 as estimated_cost_usd
FROM audio_processing_jobs
WHERE status = 'completed'
GROUP BY month
ORDER BY month DESC;
```

---

## 14. Configuration Management

### 14.1 Environment Variables

Create `.env` file (NEVER commit to git):

```bash
# Telegram Bot
TELEGRAM_TOKEN=1234567890:ABCdefGHIjklMNOpqrsTUVwxyz

# OpenAI API
OPENAI_API_KEY=sk-proj-abc123...
OPENAI_ORG_ID=org-xyz789  # Optional

# Jira
JIRA_URL=https://your-company.atlassian.net
JIRA_EMAIL=bot@company.com
JIRA_API_TOKEN=ATATT3xFf...
JIRA_PROJECT_KEY=V2A

# Google Cloud (for Docs API)
GOOGLE_APPLICATION_CREDENTIALS=./service-account.json
GOOGLE_DOCS_FOLDER_ID=1a2b3c4d5e6f7g8h

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/voice2action

# Application
APP_ENV=production
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=your-secret-key-here

# Rate Limiting
MAX_REQUESTS_PER_HOUR=10
MAX_FILE_SIZE_MB=20
MAX_AUDIO_DURATION_MINUTES=60

# Monitoring
SENTRY_DSN=https://abc123@sentry.io/456789
UPTIMEROBOT_API_KEY=ur123456

# Feature Flags
ENABLE_GOOGLE_DOCS=true
ENABLE_SALES_ANALYSIS=true
ENABLE_REAL_TIME_PROCESSING=false
```

### 14.2 Configuration Class

```python
# config.py
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    # Telegram
    TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
    
    # OpenAI
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    OPENAI_ORG_ID = os.getenv('OPENAI_ORG_ID')
    
    # Jira
    JIRA_URL = os.getenv('JIRA_URL')
    JIRA_EMAIL = os.getenv('JIRA_EMAIL')
    JIRA_API_TOKEN = os.getenv('JIRA_API_TOKEN')
    JIRA_PROJECT_KEY = os.getenv('JIRA_PROJECT_KEY', 'V2A')
    
    # Google
    GOOGLE_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
    GOOGLE_DOCS_FOLDER = os.getenv('GOOGLE_DOCS_FOLDER_ID')
    
    # Database
    DATABASE_URL = os.getenv('DATABASE_URL')
    
    # App Settings
    DEBUG = os.getenv('DEBUG', 'false').lower() == 'true'
    LOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')
    SECRET_KEY = os.getenv('SECRET_KEY')
    
    # Limits
    MAX_REQUESTS_PER_HOUR = int(os.getenv('MAX_REQUESTS_PER_HOUR', 10))
    MAX_FILE_SIZE = int(os.getenv('MAX_FILE_SIZE_MB', 20)) * 1024 * 1024
    MAX_DURATION = int(os.getenv('MAX_AUDIO_DURATION_MINUTES', 60)) * 60
    
    # Feature Flags
    ENABLE_GOOGLE_DOCS = os.getenv('ENABLE_GOOGLE_DOCS', 'true').lower() == 'true'
    ENABLE_SALES_ANALYSIS = os.getenv('ENABLE_SALES_ANALYSIS', 'true').lower() == 'true'
    
    @staticmethod
    def validate():
        """Validate required environment variables"""
        required = [
            'TELEGRAM_TOKEN',
            'OPENAI_API_KEY',
            'JIRA_URL',
            'JIRA_API_TOKEN',
            'DATABASE_URL'
        ]
        missing = [var for var in required if not os.getenv(var)]
        if missing:
            raise ValueError(f"Missing required env vars: {', '.join(missing)}")

# Validate on import
Config.validate()
```
## 14.3 Encryption Utils
```python
# utils/encrypt.py
from cryptography.fernet import Fernet
import os
import json

key = os.getenv("ENCRYPTION_KEY").encode()
cipher = Fernet(key)

def encrypt(data: dict) -> str:
    return cipher.encrypt(json.dumps(data).encode()).decode()

def decrypt(token: str) -> dict:
    return json.loads(cipher.decrypt(token.encode()).decode()
```

## 15. Prompt Engineering Guide

### 15.1 Summary Prompt
```python
SUMMARY_PROMPT = """
–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤—Å—Ç—Ä–µ—á–∏.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
- –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è
- –£–∫–∞–∂–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è
- –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π

–¢–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∏:
{transcript}

–†–µ–∑—é–º–µ:
"""
```

### 15.2 Task Extraction Prompt
```python
TASK_EXTRACTION_PROMPT = """
–ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ –∑–∞–¥–∞—á–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤—Å—Ç—Ä–µ—á–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏—Ö –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:

**–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:**
## –ó–∞–¥–∞—á–∏
1. –ó–∞–¥–∞—á–∞: [–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏]
   –î–µ–¥–ª–∞–π–Ω: [–î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –∏–ª–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"]
   –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: [–ò–º—è —á–µ–ª–æ–≤–µ–∫–∞ –∏–ª–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"]
   –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: [–í—ã—Å–æ–∫–∏–π/–°—Ä–µ–¥–Ω–∏–π/–ù–∏–∑–∫–∏–π –∏–ª–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"]

–ü—Ä–∞–≤–∏–ª–∞:
- –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —á–µ—Ç–∫–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
- –ï—Å–ª–∏ –¥–µ–¥–ª–∞–π–Ω –Ω–µ —É–ø–æ–º—è–Ω—É—Ç —è–≤–Ω–æ, –ø–∏—à–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"
- –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–µ –Ω–∞–∑–≤–∞–Ω, –ø–∏—à–∏ "–ù–µ —É–∫–∞–∑–∞–Ω"
- –ü—Ä–æ–Ω—É–º–µ—Ä—É–π –∑–∞–¥–∞—á–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É

–¢–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∏:
{transcript}

–ó–∞–¥–∞—á–∏:
"""
```

### 15.3 Sales Call Analysis Prompt
```python
SALES_ANALYSIS_PROMPT = """
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–≤–æ–Ω–æ–∫ –ø—Ä–æ–¥–∞–∂ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç.

**–ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:**

1. **–°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã**: 
   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ ("—ç—ç—ç", "–º–º–º", "—Ç–∏–ø–∞", "–∫–∞–∫ –±—ã")
   - –ü—Ä–∏–º–µ—Ä—ã —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏

2. **–ü–∞—É–∑—ã**:
   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—É–∑ >3 —Å–µ–∫—É–Ω–¥
   - –ö–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –æ–±–¥—É–º—ã–≤–∞–Ω–∏–µ)

3. **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ—á–∏**:
   - –û—Ü–µ–Ω–∫–∞: –í—ã—Å–æ–∫–∞—è / –°—Ä–µ–¥–Ω—è—è / –ù–∏–∑–∫–∞—è
   - –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ

4. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞**:
   - –ü—Ä–æ—Ü–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –≥–æ–≤–æ—Ä–µ–Ω–∏—è (–º–µ–Ω–µ–¥–∂–µ—Ä vs –∫–ª–∏–µ–Ω—Ç)
   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
   - –ù–∞–ª–∏—á–∏–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–ª—É—à–∞–Ω–∏—è

5. **–í–æ–∑—Ä–∞–∂–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞**:
   - –°–ø–∏—Å–æ–∫ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π
   - –ö–∞–∫ –º–µ–Ω–µ–¥–∂–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–ª –∫–∞–∂–¥–æ–µ

6. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
   - 3-5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
   - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∑–≤–æ–Ω–∫–∞:
{transcript}

–ê–Ω–∞–ª–∏–∑:
"""
```

### 15.4 Meeting Protocol Prompt
```python
PROTOCOL_PROMPT = """
–°–æ–∑–¥–∞–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞.

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞:**

# –ü—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏
**–î–∞—Ç–∞**: {date}
**–£—á–∞—Å—Ç–Ω–∏–∫–∏**: {participants}

## 1. –ü–æ–≤–µ—Å—Ç–∫–∞ –¥–Ω—è
[–°–ø–∏—Å–æ–∫ –æ–±—Å—É–∂–¥–∞–µ–º—ã—Ö —Ç–µ–º]

## 2. –û–±—Å—É–∂–¥–µ–Ω–∏–µ
[–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–æ–º–µ–Ω—Ç–∞–º–∏]

## 3. –ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è
[–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π —Å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º–∏]

## 4. –î–µ–π—Å—Ç–≤–∏—è
[–¢–∞–±–ª–∏—Ü–∞: –ó–∞–¥–∞—á–∞ | –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π | –°—Ä–æ–∫]

## 5. –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
[–ü–ª–∞–Ω –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –≤—Å—Ç—Ä–µ—á—É]

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:
{transcript}

–ü—Ä–æ—Ç–æ–∫–æ–ª:
"""
```

### 15.5 Prompt Best Practices

1. **Be Specific**: Clear instructions, explicit output format
2. **Use Examples**: Show desired output structure
3. **Set Constraints**: "3-5 sentences", "Format: YYYY-MM-DD"
4. **Handle Edge Cases**: "If not mentioned, write '–ù–µ —É–∫–∞–∑–∞–Ω'"
5. **Adjust Temperature**: 
   - 0.0-0.2 for structured extraction
   - 0.5-0.7 for creative summaries
6. **Test Iteratively**: Refine prompts based on output quality

---

## 16. Cost Estimation

### 16.1 API Costs per Request

| Service | Cost | Notes |
|---------|------|-------|
| **Whisper** | $0.006/min | 10-min audio = $0.06 |
| **GPT-4o-mini** | $0.15/1M input tokens | ~500 tokens = $0.00008 |
| **GPT-4o-mini** | $0.60/1M output tokens | ~800 tokens = $0.00048 |
| **Jira API** | Free | Included in Jira license |
| **Google Docs API** | Free | 60 requests/min limit |

**Example calculation (10-minute audio)**:
- Whisper: $0.06
- GPT-4o-mini: $0.00056
- **Total per request**: ~$0.061

**Monthly costs (1,000 requests)**:
- API costs: $61
- Render.com hosting: $7 (free tier)
- **Total**: ~$68/month

### 16.2 Revenue Model

| Plan | Price | Requests/month | Profit per user |
|------|-------|----------------|-----------------|
| **Free** | ‚ÇΩ0 | 3 | -‚ÇΩ12 (loss leader) |
| **Team** | ‚ÇΩ990 | 50 | ‚ÇΩ687 (‚ÇΩ990 - ‚ÇΩ303 costs) |
| **Business** | ‚ÇΩ3990 | Unlimited | ‚ÇΩ3000+ (at scale) |

**Break-even**: ~15 Team subscribers

---

## 17. Compliance & Legal

### 17.1 GDPR Compliance

**User Rights**:
- Right to access: Export all user data via `/export` command
- Right to deletion: `/delete_data` command (permanent)
- Right to portability: JSON export of all processing history
- Consent: Explicit opt-in on first use

**Implementation**:
```python
@app.command("/export_data")
async def export_user_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    
    # Fetch all data
    data = {
        "user": get_user_info(user_id),
        "jobs": get_processing_history(user_id),
        "feedback": get_user_feedback(user_id)
    }
    
    # Send as JSON file
    json_file = json.dumps(data, indent=2, ensure_ascii=False)
    await update.message.reply_document(
        document=json_file.encode(),
        filename=f"voice2action_data_{user_id}.json"
    )

@app.command("/delete_data")
async def delete_user_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    
    # Confirm deletion
    keyboard = [
        [InlineKeyboardButton("–î–∞, —É–¥–∞–ª–∏—Ç—å", callback_data="confirm_delete")],
        [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data="cancel_delete")]
    ]
    
    await update.message.reply_text(
        "‚ö†Ô∏è –í—Å–µ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –±–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å?",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )
```

### 17.2 Terms of Service (ToS)

**Key clauses**:
1. Audio files deleted after 24 hours
2. No guarantees on transcription accuracy
3. User responsible for content legality
4. API rate limits enforced
5. Service may be suspended without notice

### 17.3 Privacy Policy

**Data collected**:
- Telegram user ID (required)
- Audio files (temporary, auto-deleted)
- Processing metadata (timestamps, status)
- Feedback messages (optional)

**Data NOT collected**:
- Phone numbers
- Email addresses (unless provided)
- Location data
- Payment information (handled by payment processor)

**Third-party sharing**:
- OpenAI: Audio transcription (covered by their DPA)
- Jira: Task metadata only
- Google: Document creation (user-authorized)

---

## 18. Troubleshooting Guide

### 18.1 Common Issues

#### Bot doesn't respond
**Symptoms**: User sends message, no reply  
**Causes**:
1. Bot token expired/invalid
2. Render.com worker sleeping (free tier)
3. Network connectivity issue

**Solutions**:
```bash
# Check bot status
curl https://api.telegram.org/bot<TOKEN>/getMe

# Restart worker (Render.com)
render restart voice2action-bot

# Check logs
render logs voice2action-bot --tail 100
```

#### Transcription fails
**Symptoms**: "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ"  
**Causes**:
1. Audio too short (<1 second)
2. Corrupted file
3. Whisper API timeout

**Solutions**:
```python
# Add validation
if audio_duration < 1.0:
    await message.reply_text("–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ. –ú–∏–Ω–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞.")
    return

# Increase timeout
transcript = await asyncio.wait_for(
    transcribe_audio(file_path),
    timeout=180  # 3 minutes
)
```

#### Jira tickets not created
**Symptoms**: Summary received, but no Jira link  
**Causes**:
1. Invalid Jira credentials
2. Project doesn't exist
3. User lacks permissions

**Solutions**:
```python
# Test Jira connection
try:
    jira.projects()
    logger.info("Jira connection successful")
except Exception as e:
    logger.error(f"Jira auth failed: {e}")
    await message.reply_text(
        "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á–∏ –≤ Jira. –û—Ç–ø—Ä–∞–≤–ª–µ–Ω email –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
    )
```

### 18.2 Debug Mode

Enable verbose logging:

```python
# .env
DEBUG=true
LOG_LEVEL=DEBUG

# In code
if Config.DEBUG:
    logger.debug(f"Received audio: {file.file_id}")
    logger.debug(f"File size: {file.file_size} bytes")
    logger.debug(f"Transcript length: {len(transcript)} chars")
    logger.debug(f"GPT response: {response[:200]}...")
```

---

## 19. Migration Guide (v1.0 ‚Üí v2.0)

### 19.1 Breaking Changes
- Database schema updated (new columns)
- API response format changed (nested JSON)
- Prompt templates restructured

### 19.2 Migration Steps

```sql
-- Add new columns
ALTER TABLE audio_processing_jobs 
ADD COLUMN analysis_version VARCHAR(10) DEFAULT 'v1.0',
ADD COLUMN processing_time_seconds FLOAT,
ADD COLUMN api_cost_usd DECIMAL(10,4);

-- Migrate old data
UPDATE audio_processing_jobs 
SET analysis_version = 'v1.0'
WHERE analysis_version IS NULL;

-- Create new index
CREATE INDEX idx_jobs_version ON audio_processing_jobs(analysis_version);
```

### 19.3 Rollback Plan

```bash
# Tag current version
git tag v1.0.0

# If v2.0 fails, revert
git checkout v1.0.0
render deploy

# Restore database backup
pg_restore --clean --if-exists -d voice2action backup_v1.sql
```

---

## 20. Success Metrics (KPIs)

### 20.1 Product Metrics
- **Daily Active Users (DAU)**: Target 100+ by month 3
- **Processing success rate**: >95%
- **Average processing time**: <2 minutes
- **User retention**: 60% month-over-month

### 20.2 Technical Metrics
- **API uptime**: 99.5%
- **Average response time**: <3 seconds
- **Error rate**: <2%
- **Cost per request**: <$0.10

### 20.3 Business Metrics
- **Monthly Recurring Revenue (MRR)**: ‚ÇΩ50,000 by month 6
- **Customer Acquisition Cost (CAC)**: <‚ÇΩ500
- **Lifetime Value (LTV)**: >‚ÇΩ5,000
- **Churn rate**: <10%

### 20.4 Dashboard Queries

```sql
-- DAU
SELECT DATE(created_at) as date, COUNT(DISTINCT user_id) as dau
FROM audio_processing_jobs
WHERE created_at >= NOW() - INTERVAL '30 days'
GROUP BY date
ORDER BY date;

-- Success rate
SELECT 
  COUNT(*) FILTER (WHERE status = 'completed') * 100.0 / COUNT(*) as success_rate
FROM audio_processing_jobs
WHERE created_at >= NOW() - INTERVAL '7 days';

-- Average processing time
SELECT AVG(processing_time_seconds) as avg_time
FROM audio_processing_jobs
WHERE status = 'completed'
  AND created_at >= NOW() - INTERVAL '7 days';
```

---

## 21. Glossary

| Term | Definition |
|------|------------|
| **Transcription** | Converting audio to text using Whisper |
| **Analysis** | Extracting summary + tasks via GPT-4o-mini |
| **Job** | Single audio processing request |
| **Pipeline** | End-to-end workflow (upload ‚Üí response) |
| **Rate limiting** | Restricting requests per user/time |
| **Webhook** | HTTP callback for async notifications |
| **Polling** | Repeatedly checking job status |
| **Idempotency** | Same request produces same result |

---

## Appendix A: Sample Outputs

### A.1 Telegram Bot Response
```
‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!

üìù Summary:
–û–±—Å—É–∂–¥–µ–Ω–∏–µ —Å–ø—Ä–∏–Ω—Ç–∞ 45. –ö–æ–º–∞–Ω–¥–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∞ 5 –∑–∞–¥–∞—á –Ω–∞ –Ω–µ–¥–µ–ª—é. –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–∫—É—Å - —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥—É–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –Ω–æ–≤—ã–π API endpoint –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–æ–≤.

üìã –ó–∞–¥–∞—á–∏:
1. –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥—É–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
   üìÖ –î–µ–¥–ª–∞–π–Ω: 2025-11-08
   üë§ –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: –ê–ª–µ–∫—Å–µ–π

2. –°–æ–∑–¥–∞—Ç—å API –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–æ–≤
   üìÖ –î–µ–¥–ª–∞–π–Ω: 2025-11-10
   üë§ –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: –ú–∞—Ä–∏—è

üîó Jira:
V2A-101 | V2A-102

üìÑ Google Doc:
https://docs.google.com/document/d/abc123/edit

‚è± –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 47.3 —Å–µ–∫
```

### A.2 Web App Results Display
```html
<div class="results-card">
  <h2 class="success-header">‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞</h2>
  
  <section class="summary-box">
    <h3>üìù Summary</h3>
    <p>–û–±—Å—É–∂–¥–µ–Ω–∏–µ —Å–ø—Ä–∏–Ω—Ç–∞ 45. –ö–æ–º–∞–Ω–¥–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∞...</p>
  </section>
  
  <section class="tasks-box">
    <h3>üìã –ó–∞–¥–∞—á–∏</h3>
    <div class="task-card">
      <strong>–†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥—É–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏</strong>
      <div class="task-meta">
        <span class="deadline">üìÖ 2025-11-08</span>
        <span class="assignee">üë§ –ê–ª–µ–∫—Å–µ–π</span>
      </div>
    </div>
  </section>
  
  <section class="links-box">
    <h3>üîó –°—Å—ã–ª–∫–∏</h3>
    <a href="https://jira.com/V2A-101" target="_blank" class="jira-badge">
      V2A-101
    </a>
    <a href="https://docs.google.com/..." target="_blank" class="doc-link">
      üìÑ Google Doc
    </a>
  </section>
</div>
```

---

## Appendix B: Dependencies

### B.1 Python Requirements
```txt
# requirements.txt
python-telegram-bot==20.7
openai==1.3.0
python-dotenv==1.0.0
atlassian-python-api==3.41.0
fastapi==0.109.0
uvicorn[standard]==0.27.0
psycopg2-binary==2.9.9
sqlalchemy==2.0.25
pydub==0.25.1
google-api-python-client==2.116.0
google-auth-httplib2==0.2.0
google-auth-oauthlib==1.2.0
pytest==8.0.0
pytest-asyncio==0.23.4
pytest-cov==4.1.0
locust==2.20.1
sentry-sdk==1.40.0
openpyxl==3.1.2
python-docx==1.1.0
cryptography==42.0.5
```

---

## Appendix C: File Structure

```
voice2action-site/
‚îú‚îÄ‚îÄ telegram-bot/
‚îÇ   ‚îú‚îÄ‚îÄ bot.py                    # Main bot logic
‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio_handler.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ command_handler.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feedback_handler.py
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription.py      # Whisper API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis.py           # GPT-4o-mini
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jira_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gdocs_service.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ file_converter.py
‚îÇ       ‚îú‚îÄ‚îÄ validators.py
‚îÇ       ‚îî‚îÄ‚îÄ formatters.py
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websockets.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îî‚îÄ‚îÄ tasks/
‚îÇ       ‚îî‚îÄ‚îÄ processing_queue.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ app.html                  # Upload interface
‚îÇ   ‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ style.css
‚îÇ   ‚îî‚îÄ‚îÄ js/
‚îÇ       ‚îú‚îÄ‚îÄ main.js
‚îÇ       ‚îî‚îÄ‚îÄ upload.js
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_bot.py
‚îÇ   ‚îú‚îÄ‚îÄ test_transcription.py
‚îÇ   ‚îú‚îÄ‚îÄ test_analysis.py
‚îÇ   ‚îî‚îÄ‚îÄ test_integrations.py
‚îÇ
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ constitution.md
```

---

**Document Version**: 1.5  
**Last Updated**: 2025-11-02  
**Author**: Voice2Action Team  
**Status**: Enhanced MVP ‚Äì Ready for Scale